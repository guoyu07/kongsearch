source hotword {
  type = mysql
  sql_host = 192.168.1.63
  sql_port = 3306
  sql_user = sunyutian
  sql_pass = sun100112
  sql_db = tag
  
  sql_query_pre = SET NAMES utf8  
  #sql_query_pre = SET SESSION query_cache_type=OFF
  
  sql_query_range = SELECT MIN(id),MAX(id) FROM hotword_search
  sql_range_step = 20000
  sql_query = SELECT * FROM hotword_search WHERE id>=$start AND id<=$end
  
  sql_attr_uint = id
  sql_attr_uint = isdeleted
  
  sql_attr_string = name
}
index hotword {
  type = plain
  source = hotword
  path = /data/index/hotword/hotword
  docinfo = extern
  
  # index word(term)
  charset_type = utf-8
  charset_table = 0..9, A..Z->a..z, a..z, \
                  U+FF10..U+FF19->0..9, U+FF21..U+FF3A->a..z, U+FF41..U+FF5A->a..z, \
                  U+410..U+42F->U+430..U+44F, U+430..U+44F, U+401->U+451, U+451, \
                  U+C4->U+E4, U+D6->U+F6, U+DC->U+FC, U+DF, U+E4, U+F6, U+FC, \
                  U+0391..U+03A1->U+03B1..U+03C1, U+03A3..U+03A9->U+03C3..U+03C9, U+03B1..U+03C1, U+03C3..U+03C9, \
                  U+2E80..U+2EFF, U+2F00..U+2FDF, U+3040..U+309F, U+30A0..U+30FF, U+31F0..U+31FF, U+3105..U+312C, U+31A0..U+31BA, \
                  U+3400..U+4DB5, U+4E00..U+9FBB, U+F900..U+FAFF, U+20000..U+2A6D6, U+2A700..U+2B73F, U+2B740..U+2B81F, U+2F800..U+2FA1F
  ignore_chars = U+00AD
  blend_chars = %, -, _, ., ', U+FF05->%, U+FF0D->-, U+FF3F->_, U+FF0E->., U+FF07->'
  blend_mode = trim_none,trim_head, trim_tail, trim_both, skip_pure 
  morphology = lemmatize_en
  stopwords = /data/project/kongsearch/etc/kfz_stopwords_zh.txt /data/project/kongsearch/etc/kfz_stopwords_en.txt /data/project/kongsearch/etc/kfz_illegalwords.txt
  stopword_step = 1
  #stopwords_unstemmed = 1 #v2.1.1, bug
  wordforms = /data/project/kongsearch/etc/kfz_wordforms.txt 
  exceptions = /data/project/kongsearch/etc/kfz_exceptions.txt
  min_word_len = 1
  overshort_step = 1
  index_exact_words = 0
  dict = keywords
  embedded_limit = 4096K  #v2.1.1
  #html_strip = 1 
  #html_remove_elements = style, script
  
  ngram_len =  1
  ngram_chars = U+3000..U+2FA1F
  
  # rank for bm25a(),bm25f()
  index_field_lengths = 0
  
  # performance
  mlock = 1
  preopen = 1
}

#snippet index
source snippet {
  type = xmlpipe2
  xmlpipe_command = cat /data/index/snippet.xml
  xmlpipe_fixup_utf8 = 1
  xmlpipe_field = snippet
  xmlpipe_attr_string = id
}

index snippet:hotword {
  source = snippet
  path = /data/index/snippet
  stopwords = /data/project/kongsearch/etc/kfz_stopwords_snippet.txt
  wordforms = 
  ngram_len =  1
  ngram_chars = U+3000..U+2FA1F
}

indexer {
  mem_limit = 2047M
  write_buffer = 64M
  max_xmlpipe2_field = 8M
  lemmatizer_cache = 32M
}

searchd {
  listen = 192.168.2.152:9333:sphinx
  listen = 192.168.2.152:9322:mysql41
   pid_file = /data/logs/hotword_search/searchd.pid
        log = /data/logs/hotword_search/searchd.log
  query_log = /data/logs/hotword_search/query.log
  query_log_format = sphinxql
  
  # realtime index
  rt_flush_period = 86400
  binlog_path = /data/logs/hotword_search
  binlog_flush = 0
  binlog_max_log_size = 1024M
  
  # MPM and Network
  workers = threads
  thread_stack = 256K
  watchdog = 1
  read_timeout = 8
  client_timeout = 3600
  max_children = 768
 
  # v2.1.1, RT OPTIMIZE: (rt_merge_iops*rt_merge_maxiosize)/s
  rt_merge_iops = 40
  rt_merge_maxiosize = 2M
  
  # distributed index
  # MIN(cpu core num,local index num)
  dist_threads = 18
  
  # used with agent_persistent
  persistent_connections_limit = 128
  
  # used for agent mirrors
  #ha_period_karma = 120
  #ha_ping_interval = 30000
  
  # index
  seamless_rotate = 1
  preopen_indexes = 1
  unlink_old = 1
  
  # search
  # SetLimits() not more than max_matches
  max_matches = 10000
  # used with UpdateAttributes() 
  attr_flush_period = 1800
  # 0: disable update mva
  mva_updates_pool = 16M
  read_buffer = 2M
  read_unhinted = 32K
  subtree_docs_cache = 4M
  subtree_hits_cache = 8M
  
  collation_server = utf8_general_ci
  collation_libc_locale = C

  # client limit
  max_packet_size = 16M
  max_filters = 256
  max_filter_values = 4096
  max_batch_queries = 32
}

common {
  lemmatizer_base = /data/project/kongsearch/etc
}